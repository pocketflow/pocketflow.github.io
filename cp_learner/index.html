<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Channel Pruning - PocketFlow Docs</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Channel Pruning";
    var mkdocs_page_input_path = "cp_learner.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> PocketFlow Docs</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../installation/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../quick_start/">Quick Start</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../self_defined_models/">Self-defined Models</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Learners</span>
    <ul class="subnav">
                <li class=" current">
                    
    <a class="current" href="./">Channel Pruning</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#channel-pruning">Channel Pruning</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#introduction">Introduction</a></li>
        
            <li><a class="toctree-l4" href="#pruning-option">Pruning Option</a></li>
        
            <li><a class="toctree-l4" href="#channel-pruning-parameters">Channel pruning parameters</a></li>
        
            <li><a class="toctree-l4" href="#distilling">Distilling</a></li>
        
            <li><a class="toctree-l4" href="#group-tuning">Group Tuning</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../dcp_learner/">Discrimination-aware Channel Pruning</a>
                </li>
                <li class="">
                    
    <a class="" href="../ws_learner/">Weight Sparsification</a>
                </li>
                <li class="">
                    
    <a class="" href="../uq_learner/">Uniform Quantization</a>
                </li>
                <li class="">
                    
    <a class="" href="../nuq_learner/">Non-uniform Quantization</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../distillation/">Distillation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../multi_gpu/">Multi-GPU Training</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Hyper-parameter Optimizers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../reinforcement_learning/">Reinforcement Learning</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../performance/">Performance</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../faq/">Frequently Asked Questions</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Appendix</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../pre_trained_models/">Pre-trained Models</a>
                </li>
                <li class="">
                    
    <a class="" href="../test_cases/">Test Cases</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">PocketFlow Docs</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Learners &raquo;</li>
        
      
    
    <li>Channel Pruning</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="channel-pruning">Channel Pruning</h1>
<h2 id="introduction">Introduction</h2>
<p>Channel pruning is a kind of structural model compression approach which can not only compress the model size, but accelerate the inference speed directly. PocketFlow uses the Yihui. et. al[1] 's channel pruning algorithm to pruning each channel of convolution layers with a certain ratio, and for details please refer to the <a href="https://arxiv.org/abs/1707.06168">channel pruning paper</a>.  For better performance and more robust, we modify some parts of the algorithm to achieve better result.</p>
<p>In order to achieve a better performance, PocketFlow can take advantages of reinforcement learning to search a better compression ratio[2]. User can also use the distilling [3] and group tuning function to improve the accuracy after compression. Group tuning means setting a certain number of layers as group and then pruning and finetuning/retraining each group sequentially. For example we can set each 3 layers as a group and then pruning the first 3 layers. After that finetune/retraine the whole model and prune the next 3 layers and so on. Distilling and group tuning are experimentally proved as effective approaches to achieve higher accuracy at a certain compression ratio in most situations.</p>
<h2 id="pruning-option">Pruning Option</h2>
<p>The code of channel pruning are located at directory <code>./learners/channel_pruning</code>. To use channel pruning. users can set <code>--learners</code> to <code>channel</code>. The Channel pruning supports 3 kinds of pruning setup by <code>prune_option</code> option. </p>
<h3 id="uniform-channel-pruning">Uniform Channel Pruning</h3>
<p>One is the uniform layer pruning, which means the user can set each layer has a uniform pruning ratio by  <code>--prune_option=uniform</code> and set the ratio (eg. making the ratio 0.5) by <code>--uniform_preserve_ratio=0.5</code>.  </p>
<p><strong>Example:</strong></p>
<pre><code>./scripts/run_seven.sh nets/resnet_at_cifar10_run.py \
    --uniform_preserve_ratio=0.5 \
    --learner=channel\
    --prune_option=uniform\
    --batch_size_eval=64 \
    --resnet_size=20 
</code></pre>

<h3 id="list-channel-pruning">List Channel Pruning</h3>
<p>Another pruning option is pruning the corresponding layer with ratios listed in a named <code>ratio.list</code> file, the file name of which can be set by <code>--prune_list_file</code> option. the ratio value must be separated by a comma. User can set <code>--prune_option=list</code> to prune the model by list ratios. </p>
<p><strong>Example:</strong>
Add list <code>1.0, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 1.0, 0.25, 1.0, 0.25, 0.21875, 0.21875, 0.21875, 1.0, 0.5625, 1.0, 0.546875, 0.546875, 0.546875, 1</code> in <code>./ratio.list</code></p>
<pre><code>./scripts/run_seven.sh nets/resnet_at_cifar10_run.py \
    --learner=channel\
    --prune_option=list \
    --batch_size_eval=64 \
    --resnet_size=20 
</code></pre>

<h3 id="automatic-channel-pruning">Automatic Channel Pruning</h3>
<p>The last one pruning option is searching better pruning ratios by reinforcement learning and you only need to give a value which represents what the ratio of total FLOPs/Computation you wants the compressed model preserve. You can set <code>--prune_option=auto</code> and set a preserve ratio number such as <code>--preserve_ratio=0.5</code>.  User can also use <code>cp_nb_rlouts_min</code> to control reinforcement learning warm up iterations, which means the RL agent start to learn after the iterations, the default value is <code>50</code>. User can also use <code>cp_nb_rlouts_min</code> to control the total iteration RL agent to search, the default value is <code>200</code>. If the user want to control other parameters of the agents, please refer to the reinforcement component page.</p>
<p><strong>Example:</strong></p>
<pre><code>./scripts/run_seven.sh nets/resnet_at_cifar10_run.py \
    --preserve_ratio=0.5 \
    --learner=channel\
    --prune_option=auto \
    --batch_size_eval=64 \
    --resnet_size=20 
</code></pre>

<h2 id="channel-pruning-parameters">Channel pruning parameters</h2>
<p>The implementation of the channel pruning use Lasso algorithm to do channel selection and linear regression to do feature map reconstruction. During these two phases, sampling is done on the feature map to reduce computation cost. The users can use <code>--nb_points_per_layer</code> to set how many sampling points on each layer are taken, the default value is <code>10</code>. For some dataset, if the images contain too many zero pixels (eg. black color), the value should be greater. The users can also set using how many batches to do channel selection and feature reconstruction by <code>nb_batches</code>, the default value is <code>60</code>. Small value of  <code>nb_batches</code> may cause over-fitting and large value may slow down the solving speed, so a good value depends on the nets and dataset. For more practical usage, user may consider make the channel number of each layer is the quadruple for fast inference of mobile devices. In this case, user can set <code>--quadruple</code> to <code>True</code> to make the compressed model have a quadruple number of channels.</p>
<h2 id="distilling">Distilling</h2>
<p>Distilling is an effective approach to improve the final accuracy of compressed model with PocketFlow in most situations of classification. User can set <code>--enbl_dst=True</code> to enable distillling.</p>
<h2 id="group-tuning">Group Tuning</h2>
<p>As introduced above, group tuning was proposed by the PocketFlow team and finding it is very useful to improve the performance of model compression. In PocketFlow, users can set the group number by <code>--list_group</code>, the default value is <code>1000</code>. User can also set the number of iterations to finetune by setting <code>nb_iters_ft_ratio</code> which mean the ratio the total iterations to be used in finetuning. The learning rate of finetuning can be set by <code>lrn_rate_ft</code>. </p>
<p>[1] He, Y., Zhang, X. and Sun, J., 2017, October. Channel pruning for accelerating very deep neural networks. In <em>International Conference on Computer Vision (ICCV)</em> (Vol. 2, No. 6).</p>
<p>[2] He, Y., Lin, J., Liu, Z., Wang, H., Li, L.J. and Han, S., 2018, September. Amc: Automl for model compression and acceleration on mobile devices. In  <em>Proceedings of the European Conference on Computer Vision (ECCV)</em>  (pp. 784-800).</p>
<p>[3] Hinton, G., Vinyals, O. and Dean, J., 2015. Distilling the knowledge in a neural network. <em>arXiv preprint arXiv:1503.02531</em>.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../dcp_learner/" class="btn btn-neutral float-right" title="Discrimination-aware Channel Pruning">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../self_defined_models/" class="btn btn-neutral" title="Self-defined Models"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../self_defined_models/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../dcp_learner/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../mathjax-config.js" defer></script>
      <script src="../MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
