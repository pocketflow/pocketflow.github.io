<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Self-defined Models - PocketFlow Docs</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Self-defined Models";
    var mkdocs_page_input_path = "self_defined_models.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> PocketFlow Docs</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../installation/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../tutorial/">Tutorial</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Learners - Algorithms</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../cp_learner/">Channel Pruning</a>
                </li>
                <li class="">
                    
    <a class="" href="../dcp_learner/">Discrimination-aware Channel Pruning</a>
                </li>
                <li class="">
                    
    <a class="" href="../ws_learner/">Weight Sparsification</a>
                </li>
                <li class="">
                    
    <a class="" href="../uq_learner/">Uniform Quantization</a>
                </li>
                <li class="">
                    
    <a class="" href="../nuq_learner/">Non-uniform Quantization</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Learners - Misc.</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../distillation/">Distillation</a>
                </li>
                <li class="">
                    
    <a class="" href="../multi_gpu_training/">Multi-GPU Training</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Hyper-parameter Optimizers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../reinforcement_learning/">Reinforcement Learning</a>
                </li>
                <li class="">
                    
    <a class="" href="../automl_based_methods/">AutoML-based Methods</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Self-defined Models</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#self-defined-models">Self-defined Models</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#the-essentials">The Essentials</a></li>
        
            <li><a class="toctree-l3" href="#network-training-with-pocketflow">Network Training with PocketFlow</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../performance/">Performance</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../faq/">Frequently Asked Questions</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Appendix</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../pre_trained_models/">Pre-trained Models</a>
                </li>
                <li class="">
                    
    <a class="" href="../test_cases/">Test Cases</a>
                </li>
                <li class="">
                    
    <a class="" href="../reference/">Reference</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">PocketFlow Docs</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Self-defined Models</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="self-defined-models">Self-defined Models</h1>
<p>Self-defined models (and data sets) can be incorporated into PocketFlow by implementing a new <code>ModelHelper</code> class. The <code>ModelHelper</code> class includes the definition of data input pipeline as well as the network's forward pass and loss function. With the self-defined <code>ModelHelper</code>, the network can be either trained without any constraints using <code>FullPrecLearner</code>, or trained with certain model compression algorithms using other learners, <em>e.g.</em> <code>ChannelPrunedLearner</code> for channel pruning or <code>UniformQuantTFLearner</code> for uniform quantization. In this tutorial, we will define a 4-layer convolutional neural network (2 conv. layers + 2 dense layers) for image classification on the <a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a> data set under the PocketFlow framework. Afterwards, we shall demonstrate how to train this self-defined model with different model compression components.</p>
<h2 id="the-essentials">The Essentials</h2>
<p>To use self-defined models and data sets in PocketFlow, we need to provide the following two items in advance to describe the overall training workflow:</p>
<ul>
<li><strong>Data Input Pipeline</strong>: this tells PocketFlow how to parse features and ground-truth labels from data files.</li>
<li><strong>Network Definition</strong>: this tells PocketFlow how to compute the network's predictions and loss function's value.</li>
</ul>
<p>The <code>ModelHelper</code> class, which is a sub-class of the abstract base class <code>AbstractModelHelper</code>, is designed to provide such definitions. In PocketFlow, we have offered several <code>ModelHelper</code>  classes to describe different combinations of data sets and model architectures. To use self-defined models, a new <code>ModelHelper</code> class should be implemented. Besides, we need an execution script to call this newly defined <code>ModelHelper</code> class.</p>
<p>P.S.: You can find the full code used in this tutorial under the "./examples" directory.</p>
<h3 id="data-input-pipeline">Data Input Pipeline</h3>
<p>To start with, we need to tell PocketFlow how data files should be parsed. Here, we define a class named <code>FMnistDataset</code> to create iterators over the Fashion-MNIST training and test subsets. Every time the iterator is called, it will return a mini-batch of images and corresponding ground-truth labels.</p>
<p>Below is the full implementation of <code>FMnistDataset</code> class (this should be placed under the "./datasets" directory, named as "fmnist_dataset.py"):</p>
<pre><code class="Python">import os
import gzip
import numpy as np
import tensorflow as tf

from datasets.abstract_dataset import AbstractDataset

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_integer('nb_classes', 10, '# of classes')
tf.app.flags.DEFINE_integer('nb_smpls_train', 60000, '# of samples for training')
tf.app.flags.DEFINE_integer('nb_smpls_val', 5000, '# of samples for validation')
tf.app.flags.DEFINE_integer('nb_smpls_eval', 10000, '# of samples for evaluation')
tf.app.flags.DEFINE_integer('batch_size', 128, 'batch size per GPU for training')
tf.app.flags.DEFINE_integer('batch_size_eval', 100, 'batch size for evaluation')

# Fashion-MNIST specifications
IMAGE_HEI = 28
IMAGE_WID = 28
IMAGE_CHN = 1

def load_mnist(image_file, label_file):
  &quot;&quot;&quot;Load images and labels from *.gz files.

  This function is modified from utils/mnist_reader.py in the Fashion-MNIST repo.

  Args:
  * image_file: file path to images
  * label_file: file path to labels

  Returns:
  * images: np.array of the image data
  * labels: np.array of the label data
  &quot;&quot;&quot;

  with gzip.open(label_file, 'rb') as i_file:
    labels = np.frombuffer(i_file.read(), dtype=np.uint8, offset=8)
  with gzip.open(image_file, 'rb') as i_file:
    images = np.frombuffer(i_file.read(), dtype=np.uint8, offset=16)
    image_size = IMAGE_HEI * IMAGE_WID * IMAGE_CHN
    assert images.size == image_size * len(labels)
    images = images.reshape(len(labels), image_size)

  return images, labels

def parse_fn(image, label, is_train):
  &quot;&quot;&quot;Parse an (image, label) pair and apply data augmentation if needed.

  Args:
  * image: image tensor
  * label: label tensor
  * is_train: whether data augmentation should be applied

  Returns:
  * image: image tensor
  * label: one-hot label tensor
  &quot;&quot;&quot;

  # data parsing
  label = tf.one_hot(tf.reshape(label, []), FLAGS.nb_classes)
  image = tf.cast(tf.reshape(image, [IMAGE_HEI, IMAGE_WID, IMAGE_CHN]), tf.float32)
  image = tf.image.per_image_standardization(image)

  # data augmentation
  if is_train:
    image = tf.image.resize_image_with_crop_or_pad(image, IMAGE_HEI + 8, IMAGE_WID + 8)
    image = tf.random_crop(image, [IMAGE_HEI, IMAGE_WID, IMAGE_CHN])
    image = tf.image.random_flip_left_right(image)

  return image, label

class FMnistDataset(AbstractDataset):
  '''Fashion-MNIST dataset.'''

  def __init__(self, is_train):
    &quot;&quot;&quot;Constructor function.

    Args:
    * is_train: whether to construct the training subset
    &quot;&quot;&quot;

    # initialize the base class
    super(FMnistDataset, self).__init__(is_train)

    # choose local files or HDFS files w.r.t. FLAGS.data_disk
    if FLAGS.data_disk == 'local':
      assert FLAGS.data_dir_local is not None, '&lt;FLAGS.data_dir_local&gt; must not be None'
      data_dir = FLAGS.data_dir_local
    elif FLAGS.data_disk == 'hdfs':
      assert FLAGS.data_hdfs_host is not None and FLAGS.data_dir_hdfs is not None, \
        'both &lt;FLAGS.data_hdfs_host&gt; and &lt;FLAGS.data_dir_hdfs&gt; must not be None'
      data_dir = FLAGS.data_hdfs_host + FLAGS.data_dir_hdfs
    else:
      raise ValueError('unrecognized data disk: ' + FLAGS.data_disk)

    # setup paths to image &amp; label files, and read in images &amp; labels
    if is_train:
      self.batch_size = FLAGS.batch_size
      image_file = os.path.join(data_dir, 'train-images-idx3-ubyte.gz')
      label_file = os.path.join(data_dir, 'train-labels-idx1-ubyte.gz')
    else:
      self.batch_size = FLAGS.batch_size_eval
      image_file = os.path.join(data_dir, 't10k-images-idx3-ubyte.gz')
      label_file = os.path.join(data_dir, 't10k-labels-idx1-ubyte.gz')
    self.images, self.labels = load_mnist(image_file, label_file)
    self.parse_fn = lambda x, y: parse_fn(x, y, is_train)

  def build(self, enbl_trn_val_split=False):
    &quot;&quot;&quot;Build iterator(s) for tf.data.Dataset() object.

    Args:
    * enbl_trn_val_split: whether to split into training &amp; validation subsets

    Returns:
    * iterator_trn: iterator for the training subset
    * iterator_val: iterator for the validation subset
      OR
    * iterator: iterator for the chosen subset (training OR testing)
    &quot;&quot;&quot;

    # create a tf.data.Dataset() object from NumPy arrays
    dataset = tf.data.Dataset.from_tensor_slices((self.images, self.labels))
    dataset = dataset.map(self.parse_fn, num_parallel_calls=FLAGS.nb_threads)

    # create iterators for training &amp; validation subsets separately
    if self.is_train and enbl_trn_val_split:
      iterator_val = self.__make_iterator(dataset.take(FLAGS.nb_smpls_val))
      iterator_trn = self.__make_iterator(dataset.skip(FLAGS.nb_smpls_val))
      return iterator_trn, iterator_val

    return self.__make_iterator(dataset)

  def __make_iterator(self, dataset):
    &quot;&quot;&quot;Make an iterator from tf.data.Dataset.

    Args:
    * dataset: tf.data.Dataset object

    Returns:
    * iterator: iterator for the dataset
    &quot;&quot;&quot;

    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=FLAGS.buffer_size))
    dataset = dataset.batch(self.batch_size)
    dataset = dataset.prefetch(FLAGS.prefetch_size)
    iterator = dataset.make_one_shot_iterator()

    return iterator
</code></pre>

<p>When creating an object of <code>FMnistDataset</code> class, an extra argument named <code>is_train</code> should be provided to toggle between the training and test subsets. The data files can be either store on the local machine or the HDFS cluster, and the directory path is specified in the path configuration file, <em>e.g.</em>:</p>
<pre><code class="plain">data_dir_local_fmnist = /home/user_name/datasets/Fashion-MNIST
</code></pre>

<p>The constructor function loads images and labels from *.gz files, each stored in a NumPy array. The <code>build</code> function is then used to create a TensorFlow's data set iterator from these two NumPy arrays. Particularly, if both <code>enbl_trn_val_split</code> and <code>is_train</code> are True, then the original training subset will be divided into two parts, one for model training and the other for validation.</p>
<h3 id="network-definition">Network Definition</h3>
<p>Now we implement a new <code>ModelHelper</code> class to utilize the above data input pipeline to define the network's training workflow. Below is the full implementation of <code>ModelHelper</code> class (this should be placed under the "./nets" directory, named as "convnet_at_fmnist.py"):</p>
<pre><code class="Python">import tensorflow as tf

from nets.abstract_model_helper import AbstractModelHelper
from datasets.fmnist_dataset import FMnistDataset
from utils.lrn_rate_utils import setup_lrn_rate_piecewise_constant
from utils.multi_gpu_wrapper import MultiGpuWrapper as mgw

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_float('nb_epochs_rat', 1.0, '# of training epochs\'s ratio')
tf.app.flags.DEFINE_float('lrn_rate_init', 1e-1, 'initial learning rate')
tf.app.flags.DEFINE_float('batch_size_norm', 128, 'normalization factor of batch size')
tf.app.flags.DEFINE_float('momentum', 0.9, 'momentum coefficient')
tf.app.flags.DEFINE_float('loss_w_dcy', 3e-4, 'weight decaying loss\'s coefficient')

def forward_fn(inputs, data_format):
  &quot;&quot;&quot;Forward pass function.

  Args:
  * inputs: inputs to the network's forward pass
  * data_format: data format ('channels_last' OR 'channels_first')

  Returns:
  * inputs: outputs from the network's forward pass
  &quot;&quot;&quot;

  # tranpose the image tensor if needed
  if data_format == 'channel_first':
    inputs = tf.transpose(inputs, [0, 3, 1, 2])

  # conv1
  inputs = tf.layers.conv2d(inputs, 32, [5, 5], padding='same',
                            data_format=data_format, activation=tf.nn.relu, name='conv1')
  inputs = tf.layers.max_pooling2d(inputs, [2, 2], 2, data_format=data_format, name='pool1')

  # conv2
  inputs = tf.layers.conv2d(inputs, 64, [5, 5], padding='same',
                            data_format=data_format, activation=tf.nn.relu, name='conv2')
  inputs = tf.layers.max_pooling2d(inputs, [2, 2], 2, data_format=data_format, name='pool2')

  # fc3
  inputs = tf.layers.flatten(inputs, name='flatten')
  inputs = tf.layers.dense(inputs, 1024, activation=tf.nn.relu, name='fc3')

  # fc4
  inputs = tf.layers.dense(inputs, FLAGS.nb_classes, name='fc4')
  inputs = tf.nn.softmax(inputs, name='softmax')

  return inputs

class ModelHelper(AbstractModelHelper):
  &quot;&quot;&quot;Model helper for creating a ConvNet model for the Fashion-MNIST dataset.&quot;&quot;&quot;

  def __init__(self):
    &quot;&quot;&quot;Constructor function.&quot;&quot;&quot;

    # class-independent initialization
    super(ModelHelper, self).__init__()

    # initialize training &amp; evaluation subsets
    self.dataset_train = FMnistDataset(is_train=True)
    self.dataset_eval = FMnistDataset(is_train=False)

  def build_dataset_train(self, enbl_trn_val_split=False):
    &quot;&quot;&quot;Build the data subset for training, usually with data augmentation.&quot;&quot;&quot;

    return self.dataset_train.build(enbl_trn_val_split)

  def build_dataset_eval(self):
    &quot;&quot;&quot;Build the data subset for evaluation, usually without data augmentation.&quot;&quot;&quot;

    return self.dataset_eval.build()

  def forward_train(self, inputs, data_format='channels_last'):
    &quot;&quot;&quot;Forward computation at training.&quot;&quot;&quot;

    return forward_fn(inputs, data_format)

  def forward_eval(self, inputs, data_format='channels_last'):
    &quot;&quot;&quot;Forward computation at evaluation.&quot;&quot;&quot;

    return forward_fn(inputs, data_format)

  def calc_loss(self, labels, outputs, trainable_vars):
    &quot;&quot;&quot;Calculate loss (and some extra evaluation metrics).&quot;&quot;&quot;

    loss = tf.losses.softmax_cross_entropy(labels, outputs)
    loss += FLAGS.loss_w_dcy * tf.add_n([tf.nn.l2_loss(var) for var in trainable_vars])
    accuracy = tf.reduce_mean(
      tf.cast(tf.equal(tf.argmax(labels, axis=1), tf.argmax(outputs, axis=1)), tf.float32))
    metrics = {'accuracy': accuracy}

    return loss, metrics

  def setup_lrn_rate(self, global_step):
    &quot;&quot;&quot;Setup the learning rate (and number of training iterations).&quot;&quot;&quot;

    nb_epochs = 160
    idxs_epoch = [40, 80, 120]
    decay_rates = [1.0, 0.1, 0.01, 0.001]
    batch_size = FLAGS.batch_size * (1 if not FLAGS.enbl_multi_gpu else mgw.size())
    lrn_rate = setup_lrn_rate_piecewise_constant(global_step, batch_size, idxs_epoch, decay_rates)
    nb_iters = int(FLAGS.nb_smpls_train * nb_epochs * FLAGS.nb_epochs_rat / batch_size)

    return lrn_rate, nb_iters

  @property
  def model_name(self):
    &quot;&quot;&quot;Model's name.&quot;&quot;&quot;

    return 'convnet'

  @property
  def dataset_name(self):
    &quot;&quot;&quot;Dataset's name.&quot;&quot;&quot;

    return 'fmnist'
</code></pre>

<p>In the <code>build_dataset_train</code> and <code>build_dataset_eval</code> functions, we adopt the previously introduced <code>FMnistDataset</code> class to define the data input pipeline. The network forward-pass computation is defined in the <code>forward_train</code> and <code>forward_eval</code> functions, which corresponds to the training and evaluation graph, respectivley. The training graph is slightly different from evaluation graph, such as operations related to the batch normalization layers. The <code>calc_loss</code> function calculates the loss function's value and extra evaluation metrics, <em>e.g.</em> classification accuracy. Finally, the <code>setup_lrn_rate</code> function defines the learning rate schedule, as well as how many training iterations are need.</p>
<h3 id="execution-script">Execution Script</h3>
<p>Besides the self-defined <code>ModelHelper</code> class, we still need an execution script to pass it to the corresponding model compression component to start the training process. Below is the full implementation (this should be placed under the "./nets" directory, named as "convnet_at_fmnist_run.py"):</p>
<pre><code class="Python">import traceback
import tensorflow as tf

from nets.convnet_at_fmnist import ModelHelper
from learners.learner_utils import create_learner

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('log_dir', './logs', 'logging directory')
tf.app.flags.DEFINE_boolean('enbl_multi_gpu', False, 'enable multi-GPU training')
tf.app.flags.DEFINE_string('learner', 'full-prec', 'learner\'s name')
tf.app.flags.DEFINE_string('exec_mode', 'train', 'execution mode: train / eval')
tf.app.flags.DEFINE_boolean('debug', False, 'debugging information')

def main(unused_argv):
  &quot;&quot;&quot;Main entry.&quot;&quot;&quot;

  try:
    # setup the TF logging routine
    if FLAGS.debug:
      tf.logging.set_verbosity(tf.logging.DEBUG)
    else:
      tf.logging.set_verbosity(tf.logging.INFO)
    sm_writer = tf.summary.FileWriter(FLAGS.log_dir)

    # display FLAGS's values
    tf.logging.info('FLAGS:')
    for key, value in FLAGS.flag_values_dict().items():
      tf.logging.info('{}: {}'.format(key, value))

    # build the model helper &amp; learner
    model_helper = ModelHelper()
    learner = create_learner(sm_writer, model_helper)

    # execute the learner
    if FLAGS.exec_mode == 'train':
      learner.train()
    elif FLAGS.exec_mode == 'eval':
      learner.download_model()
      learner.evaluate()
    else:
      raise ValueError('unrecognized execution mode: ' + FLAGS.exec_mode)

    # exit normally
    return 0
  except ValueError:
    traceback.print_exc()
    return 1  # exit with errors

if __name__ == '__main__':
  tf.app.run()
</code></pre>

<h2 id="network-training-with-pocketflow">Network Training with PocketFlow</h2>
<p>To train the self-defined model without any constraint, use <code>FullPrecLearner</code>:</p>
<pre><code class="bash">$ ./scripts/run_local.sh nets/convnet_at_fmnist_run.py \
    --learner full-prec
</code></pre>

<p>To train the self-defined model with the uniform quantization constraint, use <code>UniformQuantTFLearner</code>:</p>
<pre><code class="bash">$ ./scripts/run_local.sh nets/convnet_at_fmnist_run.py \
    --learner uniform-tf
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../performance/" class="btn btn-neutral float-right" title="Performance">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../automl_based_methods/" class="btn btn-neutral" title="AutoML-based Methods"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../automl_based_methods/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../performance/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../mathjax-config.js" defer></script>
      <script src="../MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
